{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-31T03:49:30.603232Z","iopub.execute_input":"2023-10-31T03:49:30.603652Z","iopub.status.idle":"2023-10-31T03:49:30.965992Z","shell.execute_reply.started":"2023-10-31T03:49:30.603617Z","shell.execute_reply":"2023-10-31T03:49:30.965076Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/input/amazon-fine-food-reviews/hashes.txt\n/kaggle/input/amazon-fine-food-reviews/Reviews.csv\n/kaggle/input/amazon-fine-food-reviews/database.sqlite\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Amazon Fine Food Reviews Analysis\nData Source: https://www.kaggle.com/snap/amazon-fine-food-reviews\n\nEDA: https://nycdatascience.com/blog/student-works/amazon-fine-foods-visualization/\n\nThe Amazon Fine Food Reviews dataset consists of reviews of fine foods from Amazon.\n\nNumber of reviews: 568,454\nNumber of users: 256,059\nNumber of products: 74,258\nTimespan: Oct 1999 - Oct 2012\nNumber of Attributes/Columns in data: 10\n\nAttribute Information:\n\nId-\nProductId - unique identifier for the product\nUserId - unqiue identifier for the user\nProfileName\nHelpfulnessNumerator - number of users who found the review helpful{2500}\nHelpfulnessDenominator - number of users who indicated whether they found the review helpful or not{2500+100}\nScore - rating between 1 and 5\nTime - timestamp for the review\nSummary - brief summary of the review\nText - text of the review\nObjective: **Sentiment Analysis of Amazon Food Review **\nGiven a review, determine whether the review is positive (Rating of 4 or 5) or negative (rating of 1 or 2).\n\n\n[Q] How to determine if a review is positive or negative?\n\n[Ans] We could use the Score/Rating. A rating of3 or  4 or 5 could be cosnidered a positive review. A review of 1 or 2 could be considered negative.This is an approximate and proxy way of determining the polarity (positivity/negativity) of a review.\n","metadata":{}},{"cell_type":"code","source":"# importing helping libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport nltk\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n\nimport sqlite3\nimport pandas as pd\nimport numpy as np\nimport nltk\nimport string\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_curve, auc\nfrom nltk.stem.porter import PorterStemmer\n\nimport re\n# Tutorial about Python regular expressions: https://pymotw.com/2/re/\nimport string\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem.wordnet import WordNetLemmatizer\n\nfrom gensim.models import Word2Vec\nfrom gensim.models import KeyedVectors\nimport pickle\n\nfrom tqdm import tqdm\nimport os\nimport gc\nimport subprocess\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:31:12.530365Z","iopub.execute_input":"2023-10-31T15:31:12.530987Z","iopub.status.idle":"2023-10-31T15:31:25.764877Z","shell.execute_reply.started":"2023-10-31T15:31:12.530937Z","shell.execute_reply":"2023-10-31T15:31:25.764056Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"# importing data\ndf = pd.read_csv('../input/amazon-fine-food-reviews/Reviews.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:31:31.076175Z","iopub.execute_input":"2023-10-31T15:31:31.076513Z","iopub.status.idle":"2023-10-31T15:31:38.517346Z","shell.execute_reply.started":"2023-10-31T15:31:31.076486Z","shell.execute_reply":"2023-10-31T15:31:38.516258Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   Id   ProductId          UserId                      ProfileName  \\\n0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n\n   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n0                     1                       1      5  1303862400   \n1                     0                       0      1  1346976000   \n2                     1                       1      4  1219017600   \n3                     3                       3      2  1307923200   \n4                     0                       0      5  1350777600   \n\n                 Summary                                               Text  \n0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n2  \"Delight\" says it all  This is a confection that has been around a fe...  \n3         Cough Medicine  If you are looking for the secret ingredient i...  \n4            Great taffy  Great taffy at a great price.  There was a wid...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>ProductId</th>\n      <th>UserId</th>\n      <th>ProfileName</th>\n      <th>HelpfulnessNumerator</th>\n      <th>HelpfulnessDenominator</th>\n      <th>Score</th>\n      <th>Time</th>\n      <th>Summary</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>B001E4KFG0</td>\n      <td>A3SGXH7AUHU8GW</td>\n      <td>delmartian</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1303862400</td>\n      <td>Good Quality Dog Food</td>\n      <td>I have bought several of the Vitality canned d...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>B00813GRG4</td>\n      <td>A1D87F6ZCVE5NK</td>\n      <td>dll pa</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1346976000</td>\n      <td>Not as Advertised</td>\n      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>B000LQOCH0</td>\n      <td>ABXLMWJIXXAIN</td>\n      <td>Natalia Corres \"Natalia Corres\"</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1219017600</td>\n      <td>\"Delight\" says it all</td>\n      <td>This is a confection that has been around a fe...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>B000UA0QIQ</td>\n      <td>A395BORC6FGVXV</td>\n      <td>Karl</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1307923200</td>\n      <td>Cough Medicine</td>\n      <td>If you are looking for the secret ingredient i...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>B006K2ZZ7K</td>\n      <td>A1UQRSCLF8GW1T</td>\n      <td>Michael D. Bigham \"M. Wassir\"</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1350777600</td>\n      <td>Great taffy</td>\n      <td>Great taffy at a great price.  There was a wid...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:31:42.213704Z","iopub.execute_input":"2023-10-31T15:31:42.214180Z","iopub.status.idle":"2023-10-31T15:31:42.303142Z","shell.execute_reply.started":"2023-10-31T15:31:42.214148Z","shell.execute_reply":"2023-10-31T15:31:42.302226Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                  Id  HelpfulnessNumerator  HelpfulnessDenominator  \\\ncount  568454.000000         568454.000000            568454.00000   \nmean   284227.500000              1.743817                 2.22881   \nstd    164098.679298              7.636513                 8.28974   \nmin         1.000000              0.000000                 0.00000   \n25%    142114.250000              0.000000                 0.00000   \n50%    284227.500000              0.000000                 1.00000   \n75%    426340.750000              2.000000                 2.00000   \nmax    568454.000000            866.000000               923.00000   \n\n               Score          Time  \ncount  568454.000000  5.684540e+05  \nmean        4.183199  1.296257e+09  \nstd         1.310436  4.804331e+07  \nmin         1.000000  9.393408e+08  \n25%         4.000000  1.271290e+09  \n50%         5.000000  1.311120e+09  \n75%         5.000000  1.332720e+09  \nmax         5.000000  1.351210e+09  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>HelpfulnessNumerator</th>\n      <th>HelpfulnessDenominator</th>\n      <th>Score</th>\n      <th>Time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>568454.000000</td>\n      <td>568454.000000</td>\n      <td>568454.00000</td>\n      <td>568454.000000</td>\n      <td>5.684540e+05</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>284227.500000</td>\n      <td>1.743817</td>\n      <td>2.22881</td>\n      <td>4.183199</td>\n      <td>1.296257e+09</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>164098.679298</td>\n      <td>7.636513</td>\n      <td>8.28974</td>\n      <td>1.310436</td>\n      <td>4.804331e+07</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>1.000000</td>\n      <td>9.393408e+08</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>142114.250000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>4.000000</td>\n      <td>1.271290e+09</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>284227.500000</td>\n      <td>0.000000</td>\n      <td>1.00000</td>\n      <td>5.000000</td>\n      <td>1.311120e+09</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>426340.750000</td>\n      <td>2.000000</td>\n      <td>2.00000</td>\n      <td>5.000000</td>\n      <td>1.332720e+09</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>568454.000000</td>\n      <td>866.000000</td>\n      <td>923.00000</td>\n      <td>5.000000</td>\n      <td>1.351210e+09</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"## data preprocessing \n# 1. As Score is strongly related to Rating so if Score is High(>=3),then Rating is Pos\ndf[\"Ratings\"] = np.where(df['Score']>=3 , 1, 0)\ndf.head()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:31:45.948078Z","iopub.execute_input":"2023-10-31T15:31:45.948405Z","iopub.status.idle":"2023-10-31T15:31:45.968517Z","shell.execute_reply.started":"2023-10-31T15:31:45.948381Z","shell.execute_reply":"2023-10-31T15:31:45.967664Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   Id   ProductId          UserId                      ProfileName  \\\n0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n\n   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n0                     1                       1      5  1303862400   \n1                     0                       0      1  1346976000   \n2                     1                       1      4  1219017600   \n3                     3                       3      2  1307923200   \n4                     0                       0      5  1350777600   \n\n                 Summary                                               Text  \\\n0  Good Quality Dog Food  I have bought several of the Vitality canned d...   \n1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...   \n2  \"Delight\" says it all  This is a confection that has been around a fe...   \n3         Cough Medicine  If you are looking for the secret ingredient i...   \n4            Great taffy  Great taffy at a great price.  There was a wid...   \n\n   Ratings  \n0        1  \n1        0  \n2        1  \n3        0  \n4        1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>ProductId</th>\n      <th>UserId</th>\n      <th>ProfileName</th>\n      <th>HelpfulnessNumerator</th>\n      <th>HelpfulnessDenominator</th>\n      <th>Score</th>\n      <th>Time</th>\n      <th>Summary</th>\n      <th>Text</th>\n      <th>Ratings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>B001E4KFG0</td>\n      <td>A3SGXH7AUHU8GW</td>\n      <td>delmartian</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1303862400</td>\n      <td>Good Quality Dog Food</td>\n      <td>I have bought several of the Vitality canned d...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>B00813GRG4</td>\n      <td>A1D87F6ZCVE5NK</td>\n      <td>dll pa</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1346976000</td>\n      <td>Not as Advertised</td>\n      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>B000LQOCH0</td>\n      <td>ABXLMWJIXXAIN</td>\n      <td>Natalia Corres \"Natalia Corres\"</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1219017600</td>\n      <td>\"Delight\" says it all</td>\n      <td>This is a confection that has been around a fe...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>B000UA0QIQ</td>\n      <td>A395BORC6FGVXV</td>\n      <td>Karl</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1307923200</td>\n      <td>Cough Medicine</td>\n      <td>If you are looking for the secret ingredient i...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>B006K2ZZ7K</td>\n      <td>A1UQRSCLF8GW1T</td>\n      <td>Michael D. Bigham \"M. Wassir\"</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1350777600</td>\n      <td>Great taffy</td>\n      <td>Great taffy at a great price.  There was a wid...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#EDA\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import PercentFormatter\n\n#create histogram, using percentages instead of counts\nplt.hist(df['Ratings'], weights=np.ones(len(df)) / len(df))\n\n#apply percentage format to y-axis\nplt.gca().yaxis.set_major_formatter(PercentFormatter(1))\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:31:49.904042Z","iopub.execute_input":"2023-10-31T15:31:49.904393Z","iopub.status.idle":"2023-10-31T15:31:50.217676Z","shell.execute_reply.started":"2023-10-31T15:31:49.904366Z","shell.execute_reply":"2023-10-31T15:31:50.216777Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":" Negative Reviews are very less comapred to Positive Reviews","metadata":{}},{"cell_type":"code","source":"\ndf[df[\"UserId\"]== \"AR5J8UI46CURR\"]","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:31:54.302063Z","iopub.execute_input":"2023-10-31T15:31:54.302718Z","iopub.status.idle":"2023-10-31T15:31:54.416872Z","shell.execute_reply.started":"2023-10-31T15:31:54.302686Z","shell.execute_reply":"2023-10-31T15:31:54.415613Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"            Id   ProductId         UserId      ProfileName  \\\n73790    73791  B000HDOPZG  AR5J8UI46CURR  Geetha Krishnan   \n78444    78445  B000HDL1RQ  AR5J8UI46CURR  Geetha Krishnan   \n138276  138277  B000HDOPYM  AR5J8UI46CURR  Geetha Krishnan   \n138316  138317  B000HDOPYC  AR5J8UI46CURR  Geetha Krishnan   \n155048  155049  B000PAQ75C  AR5J8UI46CURR  Geetha Krishnan   \n\n        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n73790                      2                       2      5  1199577600   \n78444                      2                       2      5  1199577600   \n138276                     2                       2      5  1199577600   \n138316                     2                       2      5  1199577600   \n155048                     2                       2      5  1199577600   \n\n                                  Summary  \\\n73790   LOACKER QUADRATINI VANILLA WAFERS   \n78444   LOACKER QUADRATINI VANILLA WAFERS   \n138276  LOACKER QUADRATINI VANILLA WAFERS   \n138316  LOACKER QUADRATINI VANILLA WAFERS   \n155048  LOACKER QUADRATINI VANILLA WAFERS   \n\n                                                     Text  Ratings  \n73790   DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...        1  \n78444   DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...        1  \n138276  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...        1  \n138316  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...        1  \n155048  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...        1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>ProductId</th>\n      <th>UserId</th>\n      <th>ProfileName</th>\n      <th>HelpfulnessNumerator</th>\n      <th>HelpfulnessDenominator</th>\n      <th>Score</th>\n      <th>Time</th>\n      <th>Summary</th>\n      <th>Text</th>\n      <th>Ratings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>73790</th>\n      <td>73791</td>\n      <td>B000HDOPZG</td>\n      <td>AR5J8UI46CURR</td>\n      <td>Geetha Krishnan</td>\n      <td>2</td>\n      <td>2</td>\n      <td>5</td>\n      <td>1199577600</td>\n      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>78444</th>\n      <td>78445</td>\n      <td>B000HDL1RQ</td>\n      <td>AR5J8UI46CURR</td>\n      <td>Geetha Krishnan</td>\n      <td>2</td>\n      <td>2</td>\n      <td>5</td>\n      <td>1199577600</td>\n      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>138276</th>\n      <td>138277</td>\n      <td>B000HDOPYM</td>\n      <td>AR5J8UI46CURR</td>\n      <td>Geetha Krishnan</td>\n      <td>2</td>\n      <td>2</td>\n      <td>5</td>\n      <td>1199577600</td>\n      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>138316</th>\n      <td>138317</td>\n      <td>B000HDOPYC</td>\n      <td>AR5J8UI46CURR</td>\n      <td>Geetha Krishnan</td>\n      <td>2</td>\n      <td>2</td>\n      <td>5</td>\n      <td>1199577600</td>\n      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>155048</th>\n      <td>155049</td>\n      <td>B000PAQ75C</td>\n      <td>AR5J8UI46CURR</td>\n      <td>Geetha Krishnan</td>\n      <td>2</td>\n      <td>2</td>\n      <td>5</td>\n      <td>1199577600</td>\n      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"As can be seen above the same user has multiple reviews of the with the same values for HelpfulnessNumerator, HelpfulnessDenominator, Score, Time, Summary and Text and on doing analysis it was found that\n\nProductId=B000HDOPZG was Loacker Quadratini Vanilla Wafer Cookies, 8.82-Ounce Packages (Pack of 8)\n\nProductId=B000HDL1RQ was Loacker Quadratini Lemon Wafer Cookies, 8.82-Ounce Packages (Pack of 8) and so on\n\nIt was inferred after analysis that reviews with same parameters other than ProductId belonged to the same product just having different flavour or quantity. Hence in order to reduce redundancy it was decided to eliminate the rows having same parameters.\n\nThe method used for the same was that we first sort the data according to ProductId and then just keep the first similar product review and delelte the others. for eg. in the above just the review for ProductId=B000HDL1RQ remains. This method ensures that there is only one representative for each product and deduplication without sorting would lead to possibility of different representatives still existing for the same product.","metadata":{}},{"cell_type":"code","source":"#Sorting data according to ProductId in ascending order\nsorted_data=df.sort_values('ProductId', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:31:58.716072Z","iopub.execute_input":"2023-10-31T15:31:58.716859Z","iopub.status.idle":"2023-10-31T15:31:59.664227Z","shell.execute_reply.started":"2023-10-31T15:31:58.716827Z","shell.execute_reply":"2023-10-31T15:31:59.663413Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#Deduplication of entries\nfinal=df.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)\nfinal.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:32:01.777599Z","iopub.execute_input":"2023-10-31T15:32:01.778005Z","iopub.status.idle":"2023-10-31T15:32:02.772346Z","shell.execute_reply.started":"2023-10-31T15:32:01.777931Z","shell.execute_reply":"2023-10-31T15:32:02.771369Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(393933, 11)"},"metadata":{}}]},{"cell_type":"markdown","source":"Observation:- It was also seen that in two rows given below the value of HelpfulnessNumerator is greater than HelpfulnessDenominator which is not practically possible hence these two rows too are removed from calcualtions\n\n","metadata":{}},{"cell_type":"code","source":"final=final[final.HelpfulnessNumerator<=final.HelpfulnessDenominator]\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:32:05.199341Z","iopub.execute_input":"2023-10-31T15:32:05.199695Z","iopub.status.idle":"2023-10-31T15:32:05.267441Z","shell.execute_reply.started":"2023-10-31T15:32:05.199670Z","shell.execute_reply":"2023-10-31T15:32:05.266685Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# drop score column as we already use it and making other column Rtings\nfinal=final.drop(['Score'], axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:32:08.439346Z","iopub.execute_input":"2023-10-31T15:32:08.440004Z","iopub.status.idle":"2023-10-31T15:32:08.490365Z","shell.execute_reply.started":"2023-10-31T15:32:08.439972Z","shell.execute_reply":"2023-10-31T15:32:08.489525Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print(final.shape)\n\n#How many positive and negative reviews are present in our dataset?\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:32:10.771499Z","iopub.execute_input":"2023-10-31T15:32:10.772308Z","iopub.status.idle":"2023-10-31T15:32:10.777259Z","shell.execute_reply.started":"2023-10-31T15:32:10.772274Z","shell.execute_reply":"2023-10-31T15:32:10.776269Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"(393931, 10)\n","output_type":"stream"}]},{"cell_type":"code","source":"final['Summary'] = final['Summary'].astype(str)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:34:39.852575Z","iopub.execute_input":"2023-10-31T15:34:39.852988Z","iopub.status.idle":"2023-10-31T15:34:39.875610Z","shell.execute_reply.started":"2023-10-31T15:34:39.852926Z","shell.execute_reply":"2023-10-31T15:34:39.874527Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Text Preprocessing.\n1.In my dataset Html tags are there so we have to remove it\n2.converting all text into lowercase \n3.Removing URLS \n4.Cprrecting Spelling \n5.Removing Stop Words\n6.","metadata":{}},{"cell_type":"code","source":"# removing Html tags\n\ndef remove_tags(string):\n    result = re.sub('<.*?>','',string)\n    return result\nfinal['Text']=final['Text'].apply(lambda cw : remove_tags(cw))\nfinal.head(1)\n\n# for Summary also\ndef remove_tags(string):\n    result = str(re.sub('<.*?>','',string))\n    return result\nfinal['Summary']=final['Summary'].apply(lambda cw : remove_tags(cw))\nfinal.head(1)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:34:58.698232Z","iopub.execute_input":"2023-10-31T15:34:58.698604Z","iopub.status.idle":"2023-10-31T15:35:00.155008Z","shell.execute_reply.started":"2023-10-31T15:34:58.698575Z","shell.execute_reply":"2023-10-31T15:35:00.154015Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"   Id   ProductId          UserId ProfileName  HelpfulnessNumerator  \\\n0   1  B001E4KFG0  A3SGXH7AUHU8GW  delmartian                     1   \n\n   HelpfulnessDenominator        Time                Summary  \\\n0                       1  1303862400  Good Quality Dog Food   \n\n                                                Text  Ratings  \n0  I have bought several of the Vitality canned d...        1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>ProductId</th>\n      <th>UserId</th>\n      <th>ProfileName</th>\n      <th>HelpfulnessNumerator</th>\n      <th>HelpfulnessDenominator</th>\n      <th>Time</th>\n      <th>Summary</th>\n      <th>Text</th>\n      <th>Ratings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>B001E4KFG0</td>\n      <td>A3SGXH7AUHU8GW</td>\n      <td>delmartian</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1303862400</td>\n      <td>Good Quality Dog Food</td>\n      <td>I have bought several of the Vitality canned d...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# converting to lowercase\nfinal['Text'] = final['Text'].apply(str.lower)\nfinal.head(1)\nfinal['Summary'] = final['Summary'].apply(str.lower)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:35:34.551054Z","iopub.execute_input":"2023-10-31T15:35:34.551982Z","iopub.status.idle":"2023-10-31T15:35:34.992720Z","shell.execute_reply.started":"2023-10-31T15:35:34.551926Z","shell.execute_reply":"2023-10-31T15:35:34.991787Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Removing Punctuation\nimport string\nexclude=string.punctuation\ndef remove_punc(text):\n    for char in exclude:\n        text =text.replace(char,\"\")\n    return text\nfinal['Text']=final['Text'].apply(lambda cw : remove_punc(cw))\nfinal.head(1)\n\n# Removing Punctuation for Summary also\nimport string\nexclude=string.punctuation\ndef remove_punc(text):\n    for char in exclude:\n        text =text.replace(char,\"\")\n    return text\nfinal['Summary']=final['Summary'].apply(lambda cw : remove_punc(cw))\nfinal.head(1)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:36:10.027188Z","iopub.execute_input":"2023-10-31T15:36:10.027533Z","iopub.status.idle":"2023-10-31T15:36:18.500611Z","shell.execute_reply.started":"2023-10-31T15:36:10.027508Z","shell.execute_reply":"2023-10-31T15:36:18.499692Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"   Id   ProductId          UserId ProfileName  HelpfulnessNumerator  \\\n0   1  B001E4KFG0  A3SGXH7AUHU8GW  delmartian                     1   \n\n   HelpfulnessDenominator        Time                Summary  \\\n0                       1  1303862400  good quality dog food   \n\n                                                Text  Ratings  \n0  i have bought several of the vitality canned d...        1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>ProductId</th>\n      <th>UserId</th>\n      <th>ProfileName</th>\n      <th>HelpfulnessNumerator</th>\n      <th>HelpfulnessDenominator</th>\n      <th>Time</th>\n      <th>Summary</th>\n      <th>Text</th>\n      <th>Ratings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>B001E4KFG0</td>\n      <td>A3SGXH7AUHU8GW</td>\n      <td>delmartian</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1303862400</td>\n      <td>good quality dog food</td>\n      <td>i have bought several of the vitality canned d...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# remove urls\ndef remove_urls(text):\n    url_pattern = r'https?://\\S+|www\\.\\S+'\n    return re.sub(url_pattern, '', text)\n\n# Apply the function to the 'text' column\nfinal['Text'] = final['Text'].apply(lambda cw : remove_urls(cw))\n\n# Display the modified DataFrame\nfinal.head()\n\n# remove urls for Summary\ndef remove_urls(text):\n    url_pattern = r'https?://\\S+|www\\.\\S+'\n    return re.sub(url_pattern, '', text)\n\n# Apply the function to the 'text' column\nfinal['Summary'] = final['Summary'].apply(lambda cw : remove_urls(cw))\n\n# Display the modified DataFrame\nfinal.head()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:36:47.029821Z","iopub.execute_input":"2023-10-31T15:36:47.030654Z","iopub.status.idle":"2023-10-31T15:36:52.908340Z","shell.execute_reply.started":"2023-10-31T15:36:47.030622Z","shell.execute_reply":"2023-10-31T15:36:52.907298Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"   Id   ProductId          UserId                      ProfileName  \\\n0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n\n   HelpfulnessNumerator  HelpfulnessDenominator        Time  \\\n0                     1                       1  1303862400   \n1                     0                       0  1346976000   \n2                     1                       1  1219017600   \n3                     3                       3  1307923200   \n4                     0                       0  1350777600   \n\n                 Summary                                               Text  \\\n0  good quality dog food  i have bought several of the vitality canned d...   \n1      not as advertised  product arrived labeled as jumbo salted peanut...   \n2    delight says it all  this is a confection that has been around a fe...   \n3         cough medicine  if you are looking for the secret ingredient i...   \n4            great taffy  great taffy at a great price  there was a wide...   \n\n   Ratings  \n0        1  \n1        0  \n2        1  \n3        0  \n4        1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>ProductId</th>\n      <th>UserId</th>\n      <th>ProfileName</th>\n      <th>HelpfulnessNumerator</th>\n      <th>HelpfulnessDenominator</th>\n      <th>Time</th>\n      <th>Summary</th>\n      <th>Text</th>\n      <th>Ratings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>B001E4KFG0</td>\n      <td>A3SGXH7AUHU8GW</td>\n      <td>delmartian</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1303862400</td>\n      <td>good quality dog food</td>\n      <td>i have bought several of the vitality canned d...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>B00813GRG4</td>\n      <td>A1D87F6ZCVE5NK</td>\n      <td>dll pa</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1346976000</td>\n      <td>not as advertised</td>\n      <td>product arrived labeled as jumbo salted peanut...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>B000LQOCH0</td>\n      <td>ABXLMWJIXXAIN</td>\n      <td>Natalia Corres \"Natalia Corres\"</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1219017600</td>\n      <td>delight says it all</td>\n      <td>this is a confection that has been around a fe...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>B000UA0QIQ</td>\n      <td>A395BORC6FGVXV</td>\n      <td>Karl</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1307923200</td>\n      <td>cough medicine</td>\n      <td>if you are looking for the secret ingredient i...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>B006K2ZZ7K</td>\n      <td>A1UQRSCLF8GW1T</td>\n      <td>Michael D. Bigham \"M. Wassir\"</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1350777600</td>\n      <td>great taffy</td>\n      <td>great taffy at a great price  there was a wide...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"## Removing Stop Words\n## Stopwords : Stop words are a set of commonly used words in any language. For example, in English, the, is and and, would easily qualify as stop words. In NLP and text mining applications, stop words are used to eliminate unimportant words, allowing applications to focus on the important words instead\n## In stopwords not is also there we are removing it as not is important for review (E.g These cokkies are not good)\n ## we are removing the words from the stop words list: 'no', 'nor', 'not'\n# <br /><br /> ==> after the above steps, we are getting \"br br\"\n# we are including them into stop words list\n# instead of <br /> if we have <br/> these tags would have revmoved in the 1st step\n\nstopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n            'won', \"won't\", 'wouldn', \"wouldn't\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:37:17.901387Z","iopub.execute_input":"2023-10-31T15:37:17.901719Z","iopub.status.idle":"2023-10-31T15:37:17.913033Z","shell.execute_reply.started":"2023-10-31T15:37:17.901695Z","shell.execute_reply":"2023-10-31T15:37:17.912146Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def remove_stop(text):\n    words = text.split()\n    filtered_words = [word for word in words if word.lower() not in stopwords]\n    return ' '.join(filtered_words)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:37:24.618419Z","iopub.execute_input":"2023-10-31T15:37:24.619122Z","iopub.status.idle":"2023-10-31T15:37:24.623860Z","shell.execute_reply.started":"2023-10-31T15:37:24.619092Z","shell.execute_reply":"2023-10-31T15:37:24.622864Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"final['Text']=final['Text'].apply(lambda cw : remove_stop(cw))\nfinal.head(1)\n\n\nfinal['Summary']=final['Summary'].apply(lambda cw : remove_stop(cw))\nfinal.head(1)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:37:45.941584Z","iopub.execute_input":"2023-10-31T15:37:45.941912Z","iopub.status.idle":"2023-10-31T15:37:55.277770Z","shell.execute_reply.started":"2023-10-31T15:37:45.941886Z","shell.execute_reply":"2023-10-31T15:37:55.276833Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"   Id   ProductId          UserId ProfileName  HelpfulnessNumerator  \\\n0   1  B001E4KFG0  A3SGXH7AUHU8GW  delmartian                     1   \n\n   HelpfulnessDenominator        Time                Summary  \\\n0                       1  1303862400  good quality dog food   \n\n                                                Text  Ratings  \n0  bought several vitality canned dog food produc...        1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>ProductId</th>\n      <th>UserId</th>\n      <th>ProfileName</th>\n      <th>HelpfulnessNumerator</th>\n      <th>HelpfulnessDenominator</th>\n      <th>Time</th>\n      <th>Summary</th>\n      <th>Text</th>\n      <th>Ratings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>B001E4KFG0</td>\n      <td>A3SGXH7AUHU8GW</td>\n      <td>delmartian</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1303862400</td>\n      <td>good quality dog food</td>\n      <td>bought several vitality canned dog food produc...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import re\n\ndef decontracted(phrase):\n    # specific\n    phrase = re.sub(r\"won't\", \"will not\", phrase)\n    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n\n    # general\n    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n    return phrase\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T13:16:09.617362Z","iopub.execute_input":"2023-10-31T13:16:09.618097Z","iopub.status.idle":"2023-10-31T13:16:09.624893Z","shell.execute_reply.started":"2023-10-31T13:16:09.618061Z","shell.execute_reply":"2023-10-31T13:16:09.624040Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"stopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n            'won', \"won't\", 'wouldn', \"wouldn't\"])\n     \n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T13:16:29.156765Z","iopub.execute_input":"2023-10-31T13:16:29.157136Z","iopub.status.idle":"2023-10-31T13:16:29.168057Z","shell.execute_reply.started":"2023-10-31T13:16:29.157106Z","shell.execute_reply":"2023-10-31T13:16:29.167113Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"# Combining all the above stundents \n# one paragraph for whole preprocessing\n'''from bs4 import BeautifulSoup\nfrom tqdm import tqdm\n\npreprocessed_reviews = []\n# tqdm is for printing the status bar\nfor sentance in tqdm(final['Text'].values):\n    sentance = re.sub(r\"http\\S+\", \"\", sentance)\n    sentance = BeautifulSoup(sentance, 'lxml').get_text()\n    sentance = decontracted(sentance)\n    sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip()\n    sentance = re.sub('[^A-Za-z]+', ' ', sentance)\n    # https://gist.github.com/sebleier/554280\n    sentance = ' '.join(e.lower() for e in sentance.split() if e.lower() not in stopwords)\n    preprocessed_reviews.append(sentance.strip())'''","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:49:53.264567Z","iopub.status.idle":"2023-10-31T15:49:53.265252Z","shell.execute_reply.started":"2023-10-31T15:49:53.265047Z","shell.execute_reply":"2023-10-31T15:49:53.265073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_final=final[\"Text\"]\nimport numpy as np\n\n# Assuming new_final is a Pandas Series\ntext_array = new_final.values\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T03:50:14.039899Z","iopub.status.idle":"2023-10-31T03:50:14.040454Z","shell.execute_reply.started":"2023-10-31T03:50:14.040088Z","shell.execute_reply":"2023-10-31T03:50:14.040112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## preprocess summary\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T03:50:14.042353Z","iopub.status.idle":"2023-10-31T03:50:14.042739Z","shell.execute_reply.started":"2023-10-31T03:50:14.042530Z","shell.execute_reply":"2023-10-31T03:50:14.042547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Featurization \n## BAG OF Words\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv =CountVectorizer(max_features=5000)\nbow1=cv.fit_transform(final[\"Text\"])\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:40:20.594187Z","iopub.execute_input":"2023-10-31T15:40:20.594536Z","iopub.status.idle":"2023-10-31T15:40:40.720993Z","shell.execute_reply.started":"2023-10-31T15:40:20.594509Z","shell.execute_reply":"2023-10-31T15:40:40.719879Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"print(\"the type of count vectorizer \",type(bow))\nprint(\"the shape of out text BOW vectorizer \",bow.get_shape())\nprint(\"the number of unique words \", bow.get_shape()[1])\n## length of vector is equal to number of unique words in  reviews","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:40:45.257328Z","iopub.execute_input":"2023-10-31T15:40:45.258618Z","iopub.status.idle":"2023-10-31T15:40:45.263997Z","shell.execute_reply.started":"2023-10-31T15:40:45.258584Z","shell.execute_reply":"2023-10-31T15:40:45.262912Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"the type of count vectorizer  <class 'scipy.sparse.csr.csr_matrix'>\nthe shape of out text BOW vectorizer  (393931, 5000)\nthe number of unique words  5000\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ncv2=CountVectorizer(max_features=5000)\nbow2=cv2.fit_transform(final[\"Summary\"])\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:41:46.007298Z","iopub.execute_input":"2023-10-31T15:41:46.007684Z","iopub.status.idle":"2023-10-31T15:41:48.905502Z","shell.execute_reply.started":"2023-10-31T15:41:46.007658Z","shell.execute_reply":"2023-10-31T15:41:48.904486Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"print(\"the type of count vectorizer \",type(bow2))\nprint(\"the shape of out text BOW vectorizer \",bow2.get_shape())\nprint(\"the number of unique words \", bow2.get_shape()[1])\n## length of vector is equal to number of unique words in  reviews","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:41:54.647622Z","iopub.execute_input":"2023-10-31T15:41:54.648324Z","iopub.status.idle":"2023-10-31T15:41:54.653225Z","shell.execute_reply.started":"2023-10-31T15:41:54.648293Z","shell.execute_reply":"2023-10-31T15:41:54.652213Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"the type of count vectorizer  <class 'scipy.sparse.csr.csr_matrix'>\nthe shape of out text BOW vectorizer  (393931, 5000)\nthe number of unique words  5000\n","output_type":"stream"}]},{"cell_type":"code","source":"\n#cv.vocabulary_","metadata":{"execution":{"iopub.status.busy":"2023-10-31T03:50:14.046851Z","iopub.status.idle":"2023-10-31T03:50:14.047185Z","shell.execute_reply.started":"2023-10-31T03:50:14.047025Z","shell.execute_reply":"2023-10-31T03:50:14.047041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"the type of count vectorizer \",type(bow))\nprint(\"the shape of out text BOW vectorizer \",bow.get_shape())\nprint(\"the number of unique words \", bow.get_shape()[1])\n## length of vector is equal to number of unique words in  reviews","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:39:06.625391Z","iopub.execute_input":"2023-10-31T15:39:06.626131Z","iopub.status.idle":"2023-10-31T15:39:06.631749Z","shell.execute_reply.started":"2023-10-31T15:39:06.626096Z","shell.execute_reply":"2023-10-31T15:39:06.630759Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"the type of count vectorizer  <class 'scipy.sparse.csr.csr_matrix'>\nthe shape of out text BOW vectorizer  (393931, 5000)\nthe number of unique words  5000\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Bi-Grams and N-grams\n","metadata":{}},{"cell_type":"code","source":"# hyper parametere \n# max feature = 5000 means we are considering only top 5000 most ocurring words and rest we are ignoring it\n#cv2 = CountVectorizer(max_features=5000)\n#bow2=cv2.fit_transform(final[\"Text\"])\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T03:50:14.052610Z","iopub.status.idle":"2023-10-31T03:50:14.052959Z","shell.execute_reply.started":"2023-10-31T03:50:14.052791Z","shell.execute_reply":"2023-10-31T03:50:14.052807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#bow2.get_shape()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T03:50:14.054276Z","iopub.status.idle":"2023-10-31T03:50:14.054835Z","shell.execute_reply.started":"2023-10-31T03:50:14.054654Z","shell.execute_reply":"2023-10-31T03:50:14.054673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ngram=(1,2) means we want 1 also and 2 also\n#(1, 1) means only unigrams, (1, 2) means unigrams and bigrams, and (2, 2) means only bigrams. Only applies if analyzer is not callable.\n\n#cv3 = CountVectorizer(ngram_range=(1,2))\n#bow3=cv3.fit_transform(final[\"Text\"])\n#bow3.get_shape()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T03:50:14.056380Z","iopub.status.idle":"2023-10-31T03:50:14.056726Z","shell.execute_reply.started":"2023-10-31T03:50:14.056544Z","shell.execute_reply":"2023-10-31T03:50:14.056559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# min_dif=10,When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold\n#cv4 = CountVectorizer(ngram_range=(1,2), min_df=10)\n#bow4=cv4.fit_transform(final[\"Text\"])\n#bow4.get_shape()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T03:50:14.057974Z","iopub.status.idle":"2023-10-31T03:50:14.058299Z","shell.execute_reply.started":"2023-10-31T03:50:14.058141Z","shell.execute_reply":"2023-10-31T03:50:14.058156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**TF-IDF(Term frequency and Inverse doc frequency)**","metadata":{}},{"cell_type":"code","source":"# Term freuency TF(t,d) =no of occurence of term t in review d / total no of terms in review d \n# IDF(t)=log(total no of words in corpus /no of ducment with term t in them)\n#from sklearn.feature_extraction.text import TfidfVectorizer\n#tfidf=TfidfVectorizer()\n#fit_transform(final[\"Text\"]).toarray()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T03:50:14.059345Z","iopub.status.idle":"2023-10-31T03:50:14.059704Z","shell.execute_reply.started":"2023-10-31T03:50:14.059514Z","shell.execute_reply":"2023-10-31T03:50:14.059530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final.info()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:42:15.249043Z","iopub.execute_input":"2023-10-31T15:42:15.249413Z","iopub.status.idle":"2023-10-31T15:42:15.476401Z","shell.execute_reply.started":"2023-10-31T15:42:15.249383Z","shell.execute_reply":"2023-10-31T15:42:15.475495Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 393931 entries, 0 to 568453\nData columns (total 10 columns):\n #   Column                  Non-Null Count   Dtype \n---  ------                  --------------   ----- \n 0   Id                      393931 non-null  int64 \n 1   ProductId               393931 non-null  object\n 2   UserId                  393931 non-null  object\n 3   ProfileName             393915 non-null  object\n 4   HelpfulnessNumerator    393931 non-null  int64 \n 5   HelpfulnessDenominator  393931 non-null  int64 \n 6   Time                    393931 non-null  int64 \n 7   Summary                 393931 non-null  object\n 8   Text                    393931 non-null  object\n 9   Ratings                 393931 non-null  int64 \ndtypes: int64(5), object(5)\nmemory usage: 41.1+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Word2Vec : Captures Semantic meanings also**","metadata":{}},{"cell_type":"code","source":"len(final[\"Ratings\"])\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:51:55.800459Z","iopub.execute_input":"2023-10-31T15:51:55.801211Z","iopub.status.idle":"2023-10-31T15:51:55.807016Z","shell.execute_reply.started":"2023-10-31T15:51:55.801175Z","shell.execute_reply":"2023-10-31T15:51:55.806014Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"393931"},"metadata":{}}]},{"cell_type":"code","source":"num_feats = final[['HelpfulnessNumerator' ,'HelpfulnessDenominator']].values\n\n\n\n\nfrom scipy import sparse\n\ntraining_data = sparse.hstack(( num_feats, bow))\n\ntraining_data.shape\n\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:42:21.779166Z","iopub.execute_input":"2023-10-31T15:42:21.779504Z","iopub.status.idle":"2023-10-31T15:42:21.827293Z","shell.execute_reply.started":"2023-10-31T15:42:21.779480Z","shell.execute_reply":"2023-10-31T15:42:21.826223Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"(393931, 5002)"},"metadata":{}}]},{"cell_type":"code","source":"from scipy import sparse\n\ntraining_data_new = sparse.hstack((training_data ,bow2))\n\ntraining_data_new.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:43:30.261780Z","iopub.execute_input":"2023-10-31T15:43:30.262495Z","iopub.status.idle":"2023-10-31T15:43:30.303163Z","shell.execute_reply.started":"2023-10-31T15:43:30.262463Z","shell.execute_reply":"2023-10-31T15:43:30.302169Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"(393931, 10002)"},"metadata":{}}]},{"cell_type":"code","source":"y_train=final[\"Ratings\"]","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:52:09.781702Z","iopub.execute_input":"2023-10-31T15:52:09.782355Z","iopub.status.idle":"2023-10-31T15:52:09.786758Z","shell.execute_reply.started":"2023-10-31T15:52:09.782321Z","shell.execute_reply":"2023-10-31T15:52:09.785687Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"len(y_train)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:52:13.257344Z","iopub.execute_input":"2023-10-31T15:52:13.258285Z","iopub.status.idle":"2023-10-31T15:52:13.265911Z","shell.execute_reply.started":"2023-10-31T15:52:13.258245Z","shell.execute_reply":"2023-10-31T15:52:13.264927Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"393931"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier  # for classification tasks\nfrom sklearn.ensemble import RandomForestRegressor  # for regression tasks\nfrom sklearn.model_selection import train_test_split\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:50:26.182879Z","iopub.execute_input":"2023-10-31T15:50:26.183756Z","iopub.status.idle":"2023-10-31T15:50:26.188154Z","shell.execute_reply.started":"2023-10-31T15:50:26.183721Z","shell.execute_reply":"2023-10-31T15:50:26.187230Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(training_data_new, y_train, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:52:20.371876Z","iopub.execute_input":"2023-10-31T15:52:20.372262Z","iopub.status.idle":"2023-10-31T15:52:20.500548Z","shell.execute_reply.started":"2023-10-31T15:52:20.372237Z","shell.execute_reply":"2023-10-31T15:52:20.499527Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"clf = RandomForestClassifier(n_estimators=100, random_state=42)  # You can adjust hyperparameters\nclf.fit(X_train, y_train)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:52:31.749500Z","iopub.execute_input":"2023-10-31T15:52:31.749856Z","iopub.status.idle":"2023-10-31T16:14:25.463840Z","shell.execute_reply.started":"2023-10-31T15:52:31.749823Z","shell.execute_reply":"2023-10-31T16:14:25.462918Z"},"trusted":true},"execution_count":53,"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"RandomForestClassifier(random_state=42)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"\nfeature_importances = clf.feature_importances_\nlen(feature_importances)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:30:23.792446Z","iopub.execute_input":"2023-10-31T16:30:23.792804Z","iopub.status.idle":"2023-10-31T16:30:23.918260Z","shell.execute_reply.started":"2023-10-31T16:30:23.792780Z","shell.execute_reply":"2023-10-31T16:30:23.917275Z"},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"10002"},"metadata":{}}]},{"cell_type":"code","source":"num_features = len(cv.get_feature_names_out())\nprint(\"Number of features in BoW:\", num_features)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:31:32.254193Z","iopub.execute_input":"2023-10-31T16:31:32.254540Z","iopub.status.idle":"2023-10-31T16:31:32.266575Z","shell.execute_reply.started":"2023-10-31T16:31:32.254514Z","shell.execute_reply":"2023-10-31T16:31:32.265612Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"Number of features in BoW: 5000\n","output_type":"stream"}]},{"cell_type":"code","source":"# Assuming you have trained your classifier and obtained feature importances\n\n# Get the names of the features (words) from the CountVectorizer\nfeature_names = cv.get_feature_names_out()\n\n# Combine the feature names with their importances and sort them by importance\nfeature_importance_pairs = [(feature, importance) for feature, importance in zip(feature_names, feature_importances)]\nsorted_feature_importance_pairs = sorted(feature_importance_pairs, key=lambda x: x[1], reverse=True)\n\n# Print the top N important words and their importances\ntop_n = 100  # Change this number to the desired number of top words\nfor feature, importance in sorted_feature_importance_pairs[:top_n]:\n    print(f\"Word: {feature}, Importance: {importance}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:33:09.052260Z","iopub.execute_input":"2023-10-31T16:33:09.052599Z","iopub.status.idle":"2023-10-31T16:33:09.072555Z","shell.execute_reply.started":"2023-10-31T16:33:09.052573Z","shell.execute_reply":"2023-10-31T16:33:09.071719Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"Word: 10, Importance: 0.05660886415472105\nWord: 0g, Importance: 0.03632488108550188\nWord: options, Importance: 0.024083936384764776\nWord: greatest, Importance: 0.007298905225467996\nWord: didnt, Importance: 0.006368619332481022\nWord: house, Importance: 0.00599324805817477\nWord: tax, Importance: 0.005688630425613436\nWord: arrive, Importance: 0.005265592652918232\nWord: going, Importance: 0.005117099827094626\nWord: yeast, Importance: 0.004781212292368717\nWord: april, Importance: 0.004644697878698869\nWord: women, Importance: 0.004295887466581423\nWord: baskets, Importance: 0.004275928522421429\nWord: standard, Importance: 0.003997683448201335\nWord: product, Importance: 0.003902824094572208\nWord: die, Importance: 0.0032867185123253493\nWord: de, Importance: 0.0029414907529938805\nWord: digest, Importance: 0.0026854171139478267\nWord: bbq, Importance: 0.0026580725086563684\nWord: mad, Importance: 0.002593507794630793\nWord: grocery, Importance: 0.002484125653437713\nWord: nutella, Importance: 0.0024136175828475643\nWord: discovering, Importance: 0.002310166826000844\nWord: evenly, Importance: 0.00208076562197049\nWord: tablet, Importance: 0.0018685239216748057\nWord: described, Importance: 0.0018566100930347284\nWord: oldest, Importance: 0.0018338596609849456\nWord: finished, Importance: 0.0017954017589728948\nWord: raisin, Importance: 0.0017681768856979624\nWord: lists, Importance: 0.0017113995750418606\nWord: walmart, Importance: 0.0016907613257523288\nWord: roof, Importance: 0.0015867338349961754\nWord: children, Importance: 0.001578593768468282\nWord: wash, Importance: 0.001571305905372786\nWord: yuck, Importance: 0.0015426019664830674\nWord: nescafe, Importance: 0.0015200797149933119\nWord: diet, Importance: 0.001512819757953051\nWord: began, Importance: 0.0014903886508186826\nWord: talked, Importance: 0.0014670282533722136\nWord: code, Importance: 0.001431080209264282\nWord: mrs, Importance: 0.0014243151867274692\nWord: taffy, Importance: 0.0014148187408042987\nWord: bath, Importance: 0.0013891068935495384\nWord: building, Importance: 0.00137163021498882\nWord: quarter, Importance: 0.0013362174130530666\nWord: works, Importance: 0.0012667656105952477\nWord: supplements, Importance: 0.0012334993861728746\nWord: belgian, Importance: 0.0011876041146048723\nWord: paid, Importance: 0.0011867666515201307\nWord: pepsi, Importance: 0.0011744057420760069\nWord: looked, Importance: 0.0011714038635487907\nWord: disappear, Importance: 0.001065328362784792\nWord: approximately, Importance: 0.0010489321063625334\nWord: boyfriend, Importance: 0.001026979814581288\nWord: confident, Importance: 0.001026333016924215\nWord: disappeared, Importance: 0.0010147106779973014\nWord: tap, Importance: 0.0010036447398912947\nWord: reminds, Importance: 0.000987645054128084\nWord: excessive, Importance: 0.0009814129112577198\nWord: tail, Importance: 0.0009670070972534759\nWord: fantastic, Importance: 0.0009547942809313621\nWord: widely, Importance: 0.0009384099171762749\nWord: silky, Importance: 0.0009342432526342403\nWord: nong, Importance: 0.000906148179970022\nWord: oils, Importance: 0.0008836838780549896\nWord: floor, Importance: 0.0008820088982113047\nWord: wary, Importance: 0.0008759616350120688\nWord: yerba, Importance: 0.000872696463400916\nWord: choc, Importance: 0.0008718752121669286\nWord: minus, Importance: 0.0008525258103159514\nWord: reduced, Importance: 0.0008341036000239555\nWord: maid, Importance: 0.0008332592007448611\nWord: portion, Importance: 0.000826225210765731\nWord: example, Importance: 0.0008148220468413664\nWord: par, Importance: 0.0008126878482883396\nWord: united, Importance: 0.0008026543605041486\nWord: marketing, Importance: 0.0007988049803261161\nWord: willing, Importance: 0.0007985417566665126\nWord: substantial, Importance: 0.0007962095219438446\nWord: saved, Importance: 0.0007940787103172485\nWord: celiacs, Importance: 0.0007891559317599768\nWord: canisters, Importance: 0.000735179776987618\nWord: relative, Importance: 0.0007241017686189565\nWord: antibiotics, Importance: 0.0007187687542315355\nWord: beef, Importance: 0.0007169715621462405\nWord: wonder, Importance: 0.0007019902687571442\nWord: envelope, Importance: 0.0006987830194418767\nWord: pesto, Importance: 0.0006976747637601243\nWord: frustrating, Importance: 0.0006885779383146626\nWord: pair, Importance: 0.0006740867944616668\nWord: extremely, Importance: 0.0006645449612754402\nWord: aged, Importance: 0.0006634837882680207\nWord: accident, Importance: 0.0006624882230699614\nWord: garlic, Importance: 0.0006614820711419339\nWord: yes, Importance: 0.0006512836032493923\nWord: human, Importance: 0.0006467606299599747\nWord: wings, Importance: 0.0006380356354479846\nWord: pain, Importance: 0.0006332095598101296\nWord: rooibos, Importance: 0.0006215998504658063\nWord: order, Importance: 0.0006132944947712879\n","output_type":"stream"}]},{"cell_type":"code","source":"# For classification\ny_pred = clf.predict(X_test)\n\n# For regression\n#y_pred = reg.predict(X_test)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:15:45.776642Z","iopub.execute_input":"2023-10-31T16:15:45.776998Z","iopub.status.idle":"2023-10-31T16:15:58.746709Z","shell.execute_reply.started":"2023-10-31T16:15:45.776962Z","shell.execute_reply":"2023-10-31T16:15:58.745952Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report\n\naccuracy = accuracy_score(y_test, y_pred)\nreport = classification_report(y_test, y_pred)\n\nprint(f\"Accuracy: {accuracy}\")\nprint(\"Classification Report:\\n\", report)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:15:58.748344Z","iopub.execute_input":"2023-10-31T16:15:58.748653Z","iopub.status.idle":"2023-10-31T16:15:58.870334Z","shell.execute_reply.started":"2023-10-31T16:15:58.748627Z","shell.execute_reply":"2023-10-31T16:15:58.869361Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"Accuracy: 0.902382372726465\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.67      0.65      0.66     11401\n           1       0.94      0.94      0.94     67386\n\n    accuracy                           0.90     78787\n   macro avg       0.80      0.80      0.80     78787\nweighted avg       0.90      0.90      0.90     78787\n\n","output_type":"stream"}]}]}